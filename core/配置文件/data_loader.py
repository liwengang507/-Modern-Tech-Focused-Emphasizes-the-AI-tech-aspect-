#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡é‡‘èæ•°æ®åŠ è½½å™¨
å°†CSV/Excelæ•°æ®å¯¼å…¥åˆ°MySQLæ•°æ®åº“
"""

import pandas as pd
import mysql.connector
from mysql.connector import Error
import os
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StockDataLoader:
    """Aè‚¡é‡‘èæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, host='127.0.0.1', database='lwg_database', user='root', password=''):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            host (str): 127.0.0.1
            database (str): lwg_database
            user (str): lwg
            password (str): password123456
        """
        self.host = host
        self.database = database
        self.user = user
        self.password = password
        self.connection = None
        
    def connect(self):
        """è¿æ¥åˆ°MySQLæ•°æ®åº“"""
        try:
            self.connection = mysql.connector.connect(
                host=self.host,
                database=self.database,
                user=self.user,
                password=self.password,
                charset='utf8mb4',
                use_unicode=True
            )
            
            if self.connection.is_connected():
                logger.info(f"æˆåŠŸè¿æ¥åˆ°MySQLæ•°æ®åº“: {self.database}")
                return True
                
        except Error as e:
            logger.error(f"è¿æ¥MySQLæ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            logger.info("å·²æ–­å¼€MySQLæ•°æ®åº“è¿æ¥")
    
    def create_database(self):
        """åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        try:
            # å…ˆè¿æ¥åˆ°MySQLæœåŠ¡å™¨ï¼ˆä¸æŒ‡å®šæ•°æ®åº“ï¼‰
            temp_connection = mysql.connector.connect(
                host=self.host,
                user=self.user,
                password=self.password,
                charset='utf8mb4'
            )
            
            cursor = temp_connection.cursor()
            
            # åˆ›å»ºæ•°æ®åº“
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS {self.database} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
            logger.info(f"æ•°æ®åº“ {self.database} åˆ›å»ºæˆåŠŸæˆ–å·²å­˜åœ¨")
            
            cursor.close()
            temp_connection.close()
            
        except Error as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“å¤±è´¥: {e}")
    
    def check_table_exists(self):
        """æ£€æŸ¥æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨"""
        if not self.connection:
            logger.error("æœªè¿æ¥åˆ°æ•°æ®åº“")
            return False
            
        try:
            cursor = self.connection.cursor()
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SHOW TABLES LIKE 'stock_daily_data'")
            result = cursor.fetchone()
            
            if result:
                logger.info("æ•°æ®è¡¨ stock_daily_data å·²å­˜åœ¨")
                return True
            else:
                logger.error("æ•°æ®è¡¨ stock_daily_data ä¸å­˜åœ¨")
                return False
                
        except Error as e:
            logger.error(f"æ£€æŸ¥æ•°æ®è¡¨å¤±è´¥: {e}")
            return False
        finally:
            if cursor:
                cursor.close()
    
    def load_csv_data(self, csv_file_path, batch_size=1000):
        """
        ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            csv_file_path (str): CSVæ–‡ä»¶è·¯å¾„
            batch_size (int): æ‰¹å¤„ç†å¤§å°
        """
        if not self.connection:
            logger.error("æœªè¿æ¥åˆ°æ•°æ®åº“")
            return False
            
        if not os.path.exists(csv_file_path):
            logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
            return False
        
        try:
            logger.info(f"å¼€å§‹åŠ è½½CSVæ•°æ®: {csv_file_path}")
            
            # è¯»å–CSVæ–‡ä»¶ï¼Œå°è¯•ä¸åŒçš„ç¼–ç 
            try:
                df = pd.read_csv(csv_file_path, encoding='utf-8')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(csv_file_path, encoding='gbk')
                except UnicodeDecodeError:
                    df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
            
            logger.info(f"CSVæ–‡ä»¶è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œæ•°æ®")
            
            # æ•°æ®é¢„å¤„ç†
            df = self.preprocess_data(df)
            
            # åˆ†æ‰¹æ’å…¥æ•°æ®
            cursor = self.connection.cursor()
            
            # æ„å»ºæ’å…¥è¯­å¥ï¼ˆæ’é™¤idå­—æ®µï¼‰
            columns = [col for col in df.columns if col != 'id']
            placeholders = ', '.join(['%s'] * len(columns))
            insert_sql = f"""
                INSERT INTO stock_daily_data ({', '.join(columns)}) 
                VALUES ({placeholders})
            """
            
            total_rows = len(df)
            inserted_rows = 0
            
            for i in range(0, total_rows, batch_size):
                batch_df = df.iloc[i:i+batch_size]
                
                # å‡†å¤‡æ‰¹é‡æ’å…¥æ•°æ®
                batch_data = []
                for _, row in batch_df.iterrows():
                    values = []
                    for col in columns:  # åªä½¿ç”¨æŒ‡å®šçš„åˆ—
                        value = row[col]
                        if pd.isna(value):
                            values.append(None)
                        else:
                            values.append(value)
                    batch_data.append(tuple(values))
                
                # æ‰§è¡Œæ‰¹é‡æ’å…¥
                cursor.executemany(insert_sql, batch_data)
                self.connection.commit()
                
                inserted_rows += len(batch_data)
                logger.info(f"å·²æ’å…¥ {inserted_rows}/{total_rows} è¡Œæ•°æ®")
            
            logger.info(f"CSVæ•°æ®åŠ è½½å®Œæˆï¼Œå…±æ’å…¥ {inserted_rows} è¡Œæ•°æ®")
            return True
            
        except Error as e:
            logger.error(f"åŠ è½½CSVæ•°æ®å¤±è´¥: {e}")
            self.connection.rollback()
            return False
        except Exception as e:
            logger.error(f"å¤„ç†CSVæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
        finally:
            if cursor:
                cursor.close()
    
    def preprocess_data(self, df):
        """æ•°æ®é¢„å¤„ç†"""
        logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # æ˜¾ç¤ºCSVæ–‡ä»¶çš„åˆ—å
        logger.info(f"CSVæ–‡ä»¶åˆ—å: {list(df.columns)}")
        
        # é‡å‘½åå­—æ®µä»¥åŒ¹é…æ•°æ®åº“è¡¨ç»“æ„
        column_mapping = {
            'pre_close_price': 'prev_close_price'  # å°†pre_close_priceé‡å‘½åä¸ºprev_close_price
        }
        df = df.rename(columns=column_mapping)
        
        # å¤„ç†æ—¥æœŸå­—æ®µ
        date_columns = ['ipo_date', 'trade_date']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # å¤„ç†æ•°å€¼å­—æ®µ
        numeric_columns = [
            'open_price', 'high_price', 'low_price', 'close_price', 'prev_close_price',
            'volume', 'amount', 'pct_change', 'turnover_rate', 'pe_ttm', 'pb_ratio',
            'ps_ttm', 'pcf_ttm', 'net_profit', 'revenue', 'total_assets', 'net_assets',
            'eps', 'roe'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # å¤„ç†å­—ç¬¦ä¸²å­—æ®µ
        string_columns = [
            'stock_code', 'stock_name', 'listing_status', 'stock_type', 'trade_status',
            'is_st', 'industry_code', 'industry_name'
        ]
        
        for col in string_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).replace('nan', None)
        
        # ç§»é™¤idåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå› ä¸ºæ•°æ®åº“ä¼šè‡ªåŠ¨ç”Ÿæˆ
        if 'id' in df.columns:
            df = df.drop('id', axis=1)
        
        logger.info("æ•°æ®é¢„å¤„ç†å®Œæˆ")
        return df
    
    def get_data_summary(self):
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if not self.connection:
            logger.error("æœªè¿æ¥åˆ°æ•°æ®åº“")
            return None
            
        try:
            cursor = self.connection.cursor()
            
            # è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            summary_queries = {
                'æ€»è®°å½•æ•°': "SELECT COUNT(*) FROM stock_daily_data",
                'è‚¡ç¥¨æ•°é‡': "SELECT COUNT(DISTINCT stock_code) FROM stock_daily_data",
                'æ—¥æœŸèŒƒå›´': "SELECT MIN(trade_date), MAX(trade_date) FROM stock_daily_data",
                'è¡Œä¸šæ•°é‡': "SELECT COUNT(DISTINCT industry_code) FROM stock_daily_data WHERE industry_code IS NOT NULL"
            }
            
            summary = {}
            for key, query in summary_queries.items():
                cursor.execute(query)
                result = cursor.fetchone()
                summary[key] = result[0] if len(result) == 1 else result
            
            return summary
            
        except Error as e:
            logger.error(f"è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return None
        finally:
            if cursor:
                cursor.close()

def main():
    """ä¸»å‡½æ•°"""
    print("Aè‚¡é‡‘èæ•°æ®åŠ è½½å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨å®ä¾‹
    loader = StockDataLoader(
        host='127.0.0.1',
        database='lwg_database',
        user='root',
        password=''
    )
    
    try:
        # è¿æ¥åˆ°æ•°æ®åº“
        if not loader.connect():
            print("âŒ æ— æ³•è¿æ¥åˆ°æ•°æ®åº“ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return
        
        # æ£€æŸ¥æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
        if not loader.check_table_exists():
            print("âŒ æ•°æ®è¡¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè¡¨")
            return
        
        # åŠ è½½CSVæ•°æ®
        csv_file = "Aè‚¡é‡‘èæ—¥çº¿æ•°æ®/å®Œæ•´Aè‚¡é‡‘èæ—¥çº¿æ•°æ®.csv"
        if os.path.exists(csv_file):
            if loader.load_csv_data(csv_file):
                print("âœ… CSVæ•°æ®åŠ è½½æˆåŠŸ")
                
                # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
                summary = loader.get_data_summary()
                if summary:
                    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
                    for key, value in summary.items():
                        print(f"   - {key}: {value}")
            else:
                print("âŒ CSVæ•°æ®åŠ è½½å¤±è´¥")
        else:
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
    finally:
        loader.disconnect()

if __name__ == "__main__":
    main()
